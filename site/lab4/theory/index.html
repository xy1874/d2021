
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.6">
    
    
      
        <title>实验原理 - 深度学习体系结构（2021秋季） | 哈工大（深圳）</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a57b2b03.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../theme.css">
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="深度学习体系结构（2021秋季） | 哈工大（深圳）" class="md-header__button md-logo" aria-label="深度学习体系结构（2021秋季） | 哈工大（深圳）" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M416 48v416c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V48c0-26.51 21.49-48 48-48h224c26.51 0 48 21.49 48 48zm96 58v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42V88h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zM30 376h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            深度学习体系结构（2021秋季） | 哈工大（深圳）
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              实验原理
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://gitee.com/hitsz-cslab/dla" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    HITSZ-Course-DLA
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        首页
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../lab1/overview/" class="md-tabs__link">
        实验1：神经网络加速器设计入门
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../lab2/overview/" class="md-tabs__link">
        实验2：YOLO算法量化加速
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../lab3/overview/" class="md-tabs__link">
        实验3：基于LSTM的MNIST手写数字识别加速
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../overview/" class="md-tabs__link md-tabs__link--active">
        实验4：基于脉动阵列的CNN加速
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="深度学习体系结构（2021秋季） | 哈工大（深圳）" class="md-nav__button md-logo" aria-label="深度学习体系结构（2021秋季） | 哈工大（深圳）" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M416 48v416c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V48c0-26.51 21.49-48 48-48h224c26.51 0 48 21.49 48 48zm96 58v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42V88h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zm0 96v12a6 6 0 0 1-6 6h-18v6a6 6 0 0 1-6 6h-42v-48h42a6 6 0 0 1 6 6v6h18a6 6 0 0 1 6 6zM30 376h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6zm0-96h42v48H30a6 6 0 0 1-6-6v-6H6a6 6 0 0 1-6-6v-12a6 6 0 0 1 6-6h18v-6a6 6 0 0 1 6-6z"/></svg>

    </a>
    深度学习体系结构（2021秋季） | 哈工大（深圳）
  </label>
  
    <div class="md-nav__source">
      
<a href="https://gitee.com/hitsz-cslab/dla" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    HITSZ-Course-DLA
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          首页
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="首页" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          首页
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        实验须知
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ojguide/" class="md-nav__link">
        作业提交说明
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../vivadodl/" class="md-nav__link">
        Vivado下载链接
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          实验1：神经网络加速器设计入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实验1：神经网络加速器设计入门" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          实验1：神经网络加速器设计入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/overview/" class="md-nav__link">
        实验概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/theory/" class="md-nav__link">
        实验原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/step/" class="md-nav__link">
        实验步骤
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/submit/" class="md-nav__link">
        验收与提交
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_5" type="checkbox" id="__nav_2_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_5">
          附录
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="附录" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_5">
          <span class="md-nav__icon md-icon"></span>
          附录
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/appendix1/" class="md-nav__link">
        1. PYNQ-Z2上手指南
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab1/appendix2/" class="md-nav__link">
        2. Jupyter Notebook简介
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          实验2：YOLO算法量化加速
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实验2：YOLO算法量化加速" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          实验2：YOLO算法量化加速
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab2/overview/" class="md-nav__link">
        实验概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab2/theory/" class="md-nav__link">
        实验原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab2/step/" class="md-nav__link">
        实验步骤
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab2/extra/" class="md-nav__link">
        附加题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab2/submit/" class="md-nav__link">
        验收与提交
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          实验3：基于LSTM的MNIST手写数字识别加速
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实验3：基于LSTM的MNIST手写数字识别加速" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          实验3：基于LSTM的MNIST手写数字识别加速
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab3/overview/" class="md-nav__link">
        实验概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab3/theory/" class="md-nav__link">
        实验原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab3/step/" class="md-nav__link">
        实验步骤
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab3/extra/" class="md-nav__link">
        附加题
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lab3/submit/" class="md-nav__link">
        验收与提交
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          实验4：基于脉动阵列的CNN加速
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="实验4：基于脉动阵列的CNN加速" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          实验4：基于脉动阵列的CNN加速
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        实验概述
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          实验原理
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        实验原理
      </a>
      
        


<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 脉动阵列概述
  </a>
  
    <nav class="md-nav" aria-label="1. 脉动阵列概述">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    1.1 背景简介
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    1.2 拓扑结构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    1.3 工作原理
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-gemm" class="md-nav__link">
    2. GEMM的脉动阵列实现
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3. 卷积的脉动阵列实现
  </a>
  
    <nav class="md-nav" aria-label="3. 卷积的脉动阵列实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-im2col" class="md-nav__link">
    3.1 im2col操作
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-1" class="md-nav__link">
    3.2 方法1：固定卷积核
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-2" class="md-nav__link">
    3.2 方法2：矩阵乘法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-cnnmnist" class="md-nav__link">
    3. 基于CNN识别MNIST手写数字
  </a>
  
    <nav class="md-nav" aria-label="3. 基于CNN识别MNIST手写数字">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-cnn" class="md-nav__link">
    3.1 CNN的搭建、训练与测试
  </a>
  
    <nav class="md-nav" aria-label="3.1 CNN的搭建、训练与测试">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    &clubs; 权重初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    &clubs; 卷积和池化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    &clubs; 卷积层搭建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    &clubs; 全连接层搭建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    &clubs; 输出层搭建
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    3.2 训练和评估模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    3.3 保存并测试网络
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    3.4 网络的前向推导
  </a>
  
    <nav class="md-nav" aria-label="3.4 网络的前向推导">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    &spades; 网络参数的提取
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ip" class="md-nav__link">
    &spades; IP核的驱动/调用
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../step/" class="md-nav__link">
        实验步骤
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../submit/" class="md-nav__link">
        验收与提交
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 脉动阵列概述
  </a>
  
    <nav class="md-nav" aria-label="1. 脉动阵列概述">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    1.1 背景简介
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    1.2 拓扑结构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    1.3 工作原理
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-gemm" class="md-nav__link">
    2. GEMM的脉动阵列实现
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3. 卷积的脉动阵列实现
  </a>
  
    <nav class="md-nav" aria-label="3. 卷积的脉动阵列实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-im2col" class="md-nav__link">
    3.1 im2col操作
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-1" class="md-nav__link">
    3.2 方法1：固定卷积核
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-2" class="md-nav__link">
    3.2 方法2：矩阵乘法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-cnnmnist" class="md-nav__link">
    3. 基于CNN识别MNIST手写数字
  </a>
  
    <nav class="md-nav" aria-label="3. 基于CNN识别MNIST手写数字">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-cnn" class="md-nav__link">
    3.1 CNN的搭建、训练与测试
  </a>
  
    <nav class="md-nav" aria-label="3.1 CNN的搭建、训练与测试">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    &clubs; 权重初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    &clubs; 卷积和池化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    &clubs; 卷积层搭建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    &clubs; 全连接层搭建
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    &clubs; 输出层搭建
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    3.2 训练和评估模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    3.3 保存并测试网络
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    3.4 网络的前向推导
  </a>
  
    <nav class="md-nav" aria-label="3.4 网络的前向推导">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    &spades; 网络参数的提取
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ip" class="md-nav__link">
    &spades; IP核的驱动/调用
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="_1">实验原理</h1>
<h2 id="1">1. 脉动阵列概述</h2>
<h3 id="11">1.1 背景简介</h3>
<p>&emsp;&emsp;脉动阵列最初提出是为了解决VLSI（Very Large Scale Integration，超大规模集成电路）片上通信存在的性能瓶颈问题，属于面向特定领域而专门设计的特殊架构。脉动阵列的设计者H. T. Kung提出了<a href="http://www.eecs.harvard.edu/~htk/publication/1982-kung-why-systolic-architecture.pdf">3点设计专用系统时需要考虑的因素</a>：</p>
<ul>
<li>（1）简单性和规律性</li>
</ul>
<p>&emsp;&emsp;Kung认为在设计专用系统时，首先应当考虑的是系统的成本或代价。换言之，在满足应用需求的前提下，应当尽可能将系统的成本控制到最低。一般而言，系统的成本包括设计成本和器件成本，而其中又以设计成本为主。我们在数字逻辑设计课程中讲授过系统的模块化设计。试想如果一个系统可以被划分成若干个功能几乎完全相同的子模块，那么这个系统就可以使用一个简单的、有规律的硬件架构来实现。得益于简单性和规律性，系统将具有较低的设计成本——对于使用HDL开发电路而言，重复的模块只需要不断实例化同一个module即可。</p>
<div class="admonition note">
<p class="admonition-title">记笔记 <img alt="📐" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f4d0.svg" title=":triangular_ruler:" /></p>
<p>&emsp;&emsp;除了降低设计成本外，简单性和规律性还有利于提高系统的可扩展性。</p>
</div>
<ul>
<li>（2）并行和通信</li>
</ul>
<p>&emsp;&emsp;由Amdahl定律的延伸可知，不管是通用系统还是专用系统，只要系统中具有可并行处理的任务，那么只要使用流水线、多处理器等并行技术来加速这些任务，系统的总体性能总能够得到相应程度的提升。另外，当系统中存在大量同时工作的子模块时，子模块之间的协作和通信效率将对系统的性能造成不可忽视的影响。为了避免通信成为性能瓶颈，Kung提出的解决思路是使得子模块的通信和控制尽可能简单和规律。</p>
<ul>
<li>（3）平衡计算与I/O</li>
</ul>
<p>&emsp;&emsp;数据需要通过特定的物理接口输入到系统进行处理；处理所得结果也需要通过相应的物理接口进行输出。当I/O速率跟不上处理单元的数据运算速率时，I/O便成为了系统的性能瓶颈。一般而言，消除I/O瓶颈的方法是优化I/O通道所采用的通信协议，或改用支持更高带宽的I/O接口。这两种方法行之有效的前提条件是I/O接口所支持的最大物理带宽不小于处理单元的吞吐率。针对这个问题，Kung的方案是增加处理单元的数量，让数据在系统中多停留一段时间，从而在I/O带宽维持不变的前提下增加系统在单位时间内的数据处理能力，如图1-1所示。</p>
<p><center><img src="../assets/1-1.png" width = 400></center>
<center>图1-1 平衡计算与I/O的基本原理</center></p>
<p>&emsp;&emsp;假设在图1-1中，数据在存储器和PE之间传输需要耗费<code>100ns</code>，PE的运算延迟忽略不计。在架构1中，每<code>200ns</code>才能完成一次数据运算，因而其运算能力是5MOPS（Million Operations Per Second）。在架构2中，数据传输时延不变，但每次传输可以完成6次数据运算，因而其运算能力相比架构1提高到30MOPS。</p>
<div class="admonition hint">
<p class="admonition-title">小提示 <img alt="💡" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f4a1.svg" title=":bulb:" /></p>
<p>&emsp;&emsp;图1-2所示的平衡计算与I/O的方法同时也体现了系统设计的简单性和规律性。</p>
</div>
<p>&emsp;&emsp;需要注意的是，虽然理论上架构2的PE数量越多，其运算能力越强，但不论如何，数据传输时延都需要200ns。这意味着这种类型的架构只适合那些对传输带宽要求较低的计算密集型应用。</p>
<h3 id="12">1.2 拓扑结构</h3>
<p>&emsp;&emsp;脉动阵列的定义有很多版本，但一般指的是一种按照特定规律连接起来的流水式同构多处理器架构。脉动阵列由若干个完全相同的PE（Processing Element，处理单元）构成，并且一般每一个PE都仅与其相邻的PE进行连接。如图1-2所示。</p>
<p><center><img src="../assets/1-2.png" width = 650></center>
<center>图1-2 脉动阵列的几种拓扑结构</center></p>
<p>&emsp;&emsp;在图1-2中，不管采用哪一种连接方式，数据都按照一定的规律有节奏地在阵列中传播。当数据传播到一定次数之后，脉动阵列完成计算并产生所需的结果。</p>
<p>&emsp;&emsp;脉动阵列的结构具有良好的简单性和规律性，其基本特点是各个PE完全相同，并且PE只与其相邻的PE进行数据通信。与数据广播所需的总线连接方式相比，脉动阵列采取的连接方式具有更短的物理线路，更低的扇出，不仅有利于降低PE间的通信延迟，还降低了电路布局布线的难度，从而提高了电路的工作频率。但是，脉动阵列的结构同时也限制了它只适合用于带宽要求较低且运算具有较大规律性的应用场合，比如矩阵乘法、卷积、排序、多项式计算等。</p>
<h3 id="13">1.3 工作原理</h3>
<p>&emsp;&emsp;脉动阵列本质是结构简单的流水线，其工作过程可看作是数据在时钟的驱动下像脉搏一般在阵列中向前跳动，如图1-3所示。</p>
<p><center><img src="../assets/1-3.png" width = 450></center>
<center>图1-3 脉动阵列工作原理</center></p>
<h2 id="2-gemm">2. GEMM的脉动阵列实现</h2>
<p>&emsp;&emsp;GEMM（GEneral Matrix Multiply，通用矩阵乘法）中存在大量的MAC（Multiply and ACcumulate, 乘累加）运算，具有运算量较大、运算种类单一的特点，因而非常适合使用脉动阵列来实现GEMM。</p>
<p>&emsp;&emsp;设有矩阵<script type="math/tex">\pmb A_{3 \times 3}</script>、<script type="math/tex">\pmb B_{3 \times 4}</script>：</p>
<p>
<script type="math/tex; mode=display">
\pmb A = \left[
    \begin{matrix}
        a_{00} & a_{01} & a_{02} \\
        a_{10} & a_{11} & a_{12} \\
        a_{20} & a_{21} & a_{22}
    \end{matrix}
    \right],{\quad}
\pmb B = \left[
    \begin{matrix}
        b_{00} & b_{01} & b_{02} & b_{03} \\
        b_{10} & b_{11} & b_{12} & b_{13} \\
        b_{20} & b_{21} & b_{22} & b_{23}
    \end{matrix}
    \right].
</script>
</p>
<p>&emsp;&emsp;使用脉动阵列计算矩阵<script type="math/tex">\pmb C = \pmb A \cdot \pmb B</script>时，需要将<script type="math/tex">\pmb A</script>、<script type="math/tex">\pmb B</script>的数据分多次输入阵列，如图1-4所示。</p>
<p><center><img src="../assets/1-4.png" width = 540></center>
<center>图1-4 脉动阵列计算矩阵乘法的初始状态</center></p>
<p>&emsp;&emsp;第1拍时，左侧和上方缓存内的矩阵数据开始流入脉动阵列，并开始计算<script type="math/tex">c_{00}</script>，如图1-5所示。</p>
<p><center><img src="../assets/1-5.png" width = 580></center>
<center>图1-5 脉动阵列计算矩阵乘法的第1个时钟</center></p>
<p>&emsp;&emsp;同样的，第2拍时，缓存内的数据继续流入脉动阵列，并开始计算<script type="math/tex">c_{01}</script>和<script type="math/tex">c_{10}</script>、继续计算<script type="math/tex">c_{00}</script>，如图1-6所示。</p>
<p><center><img src="../assets/1-6.png" width = 620></center>
<center>图1-6 脉动阵列计算矩阵乘法的第2个时钟</center></p>
<p>&emsp;&emsp;第3拍时，开始计算<script type="math/tex">c_{02}</script>、<script type="math/tex">c_{11}</script>和<script type="math/tex">c_{20}</script>，继续计算<script type="math/tex">c_{01}</script>和<script type="math/tex">c_{10}</script>，而此时<script type="math/tex">c_{00}</script>计算完毕，如图1-7所示。</p>
<p><center><img src="../assets/1-7.png"></center>
<center>图1-7 第3个时钟时<script type="math/tex">c_{00}</script>计算完毕</center></p>
<p>&emsp;&emsp;依此类推，第4拍时<script type="math/tex">c_{01}</script>和<script type="math/tex">c_{10}</script>计算完成；第5拍时<script type="math/tex">c_{02}</script>、<script type="math/tex">c_{11}</script>和<script type="math/tex">c_{20}</script>计算完成，等等。直到第8拍时，矩阵<script type="math/tex">\pmb C</script>的最后一个元素<script type="math/tex">c_{23}</script>计算完成。</p>
<h2 id="3">3. 卷积的脉动阵列实现</h2>
<p>&emsp;&emsp;卷积与矩阵乘法类似，也含有大量的MAC运算，同样具有运算量较大、运算种类单一的特点，因而也适合使用脉动阵列来实现。</p>
<p>&emsp;&emsp;一维卷积可以通过递推公式<script type="math/tex">y_{n+1} = y_n + w_{n+1} \cdot x_{n+1}</script>很容易地得出相应的一维脉动阵列架构的实现。因此，此处仅讨论如何使用脉动阵列实现三维卷积。</p>
<h3 id="31-im2col">3.1 im2col操作</h3>
<p>&emsp;&emsp;为了方便处理，在使用脉动阵列实现三维卷积时，需要先对卷积的输入特征图进行im2col处理。卷积时，卷积核相当于一个滑动窗口，不停地在输入特征图上从左到右、从上到下滑动。所谓im2col处理，就是将当前滑动窗口下的特征图数据进行展开和重排，如图1-8所示。</p>
<p><center><img src="../assets/1-8.png" width = 600></center>
<center>图1-8 im2col原理</center></p>
<p>&emsp;&emsp;类似地，卷积核也需要进行相应的展开操作。需要注意的是，输入特征图滑动窗口内的数据被展开成列向量，而卷积核则被展开成行向量。</p>
<p>&emsp;&emsp;设有3通道的输入特征图<script type="math/tex">(\pmb R, \pmb G, \pmb B)</script>，以及2个卷积核<script type="math/tex">\pmb f_0</script>和<script type="math/tex">\pmb f_1</script>，分别对它们进行im2col操作之后，得到相应的展开后的矩阵数据，如图1-9所示。</p>
<p><center><img src="../assets/1-9.png"></center>
<font size = 2>注：右下角的矩阵<script type="math/tex">\pmb Y</script>对应于卷积运算的结果（输出特征图的尺寸是2<script type="math/tex">\times</script>2、2通道）。</font>
<center>图1-9 im2col处理前后的特征图和卷积核</center></p>
<h3 id="32-1">3.2 方法1：固定卷积核</h3>
<p>&emsp;&emsp;展开完成后，一种方法是将卷积核的权值数据存储在脉动阵列的PE当中，然后令特征图数据从左侧输入脉动阵列并向右传播、令卷积中间结果从上往下传播。此时，脉动阵列的初始状态如图1-10所示。</p>
<p><center><img src="../assets/1-10.png"></center>
<center>图1-10 脉动阵列计算三维卷积的初始状态</center></p>
<p>&emsp;&emsp;第1拍时，特征图数据从左侧的缓存流入脉动阵列，开始计算<script type="math/tex">y_{00}</script>，如图1-11所示。</p>
<p><center><img src="../assets/1-11.png"></center>
<center>图1-11 脉动阵列计算三维卷积的第1个时钟</center></p>
<p>&emsp;&emsp;第2拍时，开始计算<script type="math/tex">y_{01}</script>和<script type="math/tex">y'_{00}</script>，而<script type="math/tex">y_{00}</script>则向下传播，如图1-12所示。</p>
<p><center><img src="../assets/1-12.png"></center>
<center>图1-12 脉动阵列计算三维卷积的第2个时钟</center></p>
<p>&emsp;&emsp;依此类推，一直到第12拍时，<script type="math/tex">y_{00}</script>计算完成并从脉动阵列下方流出，如图1-13所示。</p>
<p><center><img src="../assets/1-13.png"></center>
<center>图1-13 脉动阵列计算三维卷积的第12个时钟</center></p>
<p>&emsp;&emsp;接下来，从第13拍到第15拍，每一拍都流出2个矩阵<script type="math/tex">\pmb Y</script>的元素。最后一个元素将在第16拍流出，此时计算结束。</p>
<div class="admonition warning">
<p class="admonition-title">注意 <img alt="🔫" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f52b.svg" title=":gun:" /></p>
<p>&emsp;&emsp;矩阵<script type="math/tex">\pmb Y</script>的尺寸和形状与输出特征图的形状不同。因此，在真正输出结果之前，需要对矩阵<script type="math/tex">\pmb Y</script>的元素进行重新排布，从而将其还原成输出特征图应有的尺寸和形状。</p>
</div>
<h3 id="32-2">3.2 方法2：矩阵乘法</h3>
<p>&emsp;&emsp;显然，要想用脉动阵列实现三维卷积，除了上述方法之外，还可以在im2col操作之后，直接将其当成普通的矩阵乘法处理。</p>
<div class="admonition question">
<p class="admonition-title">动动脑筋 <img alt="💫" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f4ab.svg" title=":dizzy:" /></p>
<p>&emsp;&emsp;请对比上述两种方法的优缺点。</p>
</div>
<h2 id="3-cnnmnist">3. 基于CNN识别MNIST手写数字</h2>
<h3 id="31-cnn">3.1 CNN的搭建、训练与测试</h3>
<p>&emsp;&emsp;本实验使用一个四层的CNN网络来实现手写数字0-9的识别。相关代码在虚拟机<code>~/tensorflow/MNIST</code>的目录下，训练代码为<code>mnist_int16_test.py</code>和<code>input_data.py</code>。</p>
<p>&emsp;&emsp;在终端中输入如下命令，即可开始网络训练：</p>
<div class="highlight"><pre><span></span><code>$&gt; <span class="nb">cd</span> /home/cs/tensorflow/MNIST
$&gt; python mnist_int16_test.py
</code></pre></div>
<p>&emsp;&emsp;本实验所使用的CNN，其网络结构如图1-14所示。</p>
<p><center></p>
<table><tbody>
    <tr><th>Convolutional Layer1 + ReLU + MAX Pooling</th></tr>
    <tr><th>Convolutional Layer2 + ReLU + MAX Pooling</th></tr>
    <tr><th>Fully Connected Layer1 + ReLU + Dropout</th></tr>
    <tr><th>Fully Connected Layer2 To Prediction</th></tr>
</table>

<p></center>
<center>图1-14 本实验的CNN网络结构</center></p>
<p>&emsp;&emsp;接下来，逐一介绍CNN权重初始化以及各网络层的实现方法。</p>
<h4 id="_2">&clubs; 权重初始化</h4>
<p>&emsp;&emsp;建立模型时，需要对网络权值和偏置进行初始化。初始化权值时，应加入少量噪声来打破对称性和避免零梯度。由于我们使用了ReLU神经元，因此比较好的做法是用一个较小的正数来初始化网络偏置，以避免神经元节点输出恒为0的问题（Dead Neurons）。</p>
<p>&emsp;&emsp;为了避免建立模型时的反复初始化，定义两个初始化函数，如图1-15所示。</p>
<p><center><img src="../assets/1-15.png" width = 450></center>
<center>图1-15 初始化函数</center></p>
<h4 id="_3">&clubs; 卷积和池化</h4>
<p>&emsp;&emsp;TensorFlow在卷积和池化上有很强的灵活性。卷积使用1步长（Stride）、0边距（Padding）的模板，保证输出的维度和输入相同。池化则使用传统的2×2模板做最大池化。为了代码更简洁，这部分被定义成函数，如图1-16所示。</p>
<p><center><img src="../assets/1-16.png" width = 600></center>
<center>图1-16 卷积和池化的配置函数</center></p>
<h4 id="_4">&clubs; 卷积层搭建</h4>
<p>&emsp;&emsp;第一层由一个卷积接一个最大池化完成。卷积在每个3×3的Patch中算出16个特征。卷积的权重张量形状是[3, 3, 1, 16]，前两个维度是Patch的大小，接着分别是输入和输出的通道数。每个输出通道都有一个与之对应的偏置量。接下来将卷积核与输入的x_image进行卷积，并通过ReLU激活函数，再做最大池化处理，如图1-17所示。</p>
<p><center><img src="../assets/1-17.png" width = 550></center>
<center>图1-17 第1层卷积实现</center></p>
<p>&emsp;&emsp;第二层构建一个更深的网络，每个3×3的Patch会得到32个特征。卷积核大小3×3×16，数量为32个，构造过程类似上一层，如图1-18所示。</p>
<p><center><img src="../assets/1-18.png" width = 550></center>
<center>图1-18 第2层卷积实现</center></p>
<h4 id="_5">&clubs; 全连接层搭建</h4>
<p>&emsp;&emsp;原始图片尺寸是28×28，经过两次2×2的池化后，长宽尺寸降低到7×7。现在加入一个128个神经元的全连接层，将上一层输出的结果Vector化，变成一个向量，将其与权重W_fc1相乘，加上偏置b_fc1，对其使用ReLU，如图1-19所示。</p>
<p><center><img src="../assets/1-19.png" width = 550></center>
<center>图1-19 全连接层实现</center></p>
<p>&emsp;&emsp;为了减少过拟合，我们在输出层之前加入dropout。我们用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout，如图1-20所示。</p>
<p><center><img src="../assets/1-20.png" width = 450></center>
<center>图1-20 添加dropout</center></p>
<p>&emsp;&emsp;TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。</p>
<h4 id="_6">&clubs; 输出层搭建</h4>
<p>&emsp;&emsp;最后一层使用全连接层，并通过Softmax回归来输出预测结果。</p>
<p>&emsp;&emsp;Softmax模型可以用来给不同的对象分配概率，如图1-21所示。对于输入的x_i加权求和，再分别加上一个偏置量，最后再输入到Softmax函数中。</p>
<p><center><img src="../assets/1-21.png" width = 400></center>
<center>图1-21 Softmax模型示意图</center></p>
<p>&emsp;&emsp;Softmax函数的计算公式为：</p>
<p>
<script type="math/tex; mode=display"> evidence_i = \sum_{j} W_{i,j} x_j + b_i \tag {1-1} </script>
</p>
<p>
<script type="math/tex; mode=display"> y=softmax(evdience) \tag {1-2} </script>
</p>
<p>
<script type="math/tex; mode=display"> softmax(x)=normalize(exp⁡(x)) \tag {1-3} </script>
</p>
<p>
<script type="math/tex; mode=display"> {softmax(x)}_i = \frac {exp⁡(x_i)} {\sum_{j} exp⁡(x_j)} \tag {1-4} </script>
</p>
<p>&emsp;&emsp;Softmax层的实现如图1-22所示。</p>
<p><center><img src="../assets/1-22.png" width = 600></center>
<center>图1-22 Softmax层实现</center></p>
<h3 id="32">3.2 训练和评估模型</h3>
<p>&emsp;&emsp;训练模型前，首先定义损失函数（Loss Function），并在训练过程中尽量最小化这个指标。这里使用的损失函数是"交叉熵"（Cross-Entropy）。交叉熵产生于信息论里面的信息压缩编码技术，但是它后来演变成为从博弈论到机器学习等其他领域里的重要技术手段。它的定义如下：</p>
<p>
<script type="math/tex; mode=display"> H_{y'} = - \sum_{i} {y'}_i log(y_i) \tag {1-5} </script>
</p>
<p>&emsp;&emsp;计算交叉熵后，就可以使用梯度下降来优化参数。由于前面已经部署好网络结构，所以TensorFlow可以使用反向传播算法计算梯度，自动地优化参数，直到交叉熵最小。TensorFlow提供了多种优化器，这里选择更加复杂的Adam优化器来做梯度最速下降，学习率0.0001，如图1-23所示。</p>
<p><center><img src="../assets/1-23.png" width = 650></center>
<center>图1-23 利用Adam优化器实现梯度最速下降</center></p>
<p>&emsp;&emsp;每次训练随机选择50个样本，加快训练速度，每轮训练结束后，计算预测准确度，如图1-24所示。</p>
<p><center><img src="../assets/1-24.png" width = 650></center>
<center>图1-24 随机选取50个样本加速训练</center></p>
<p>&emsp;&emsp;在CNN网络训练过程中，通过TensorFlow中的可视化工具Tensorboard，可以跟踪网络的整个训练过程中的信息，比如每次循环过程中的参数变化、损失变化等。输入如下命令，即可打开Tensorboard工具：</p>
<div class="highlight"><pre><span></span><code>$&gt; tensorboard –logdir<span class="o">=</span>logs
</code></pre></div>
<p>&emsp;&emsp;运行上述命令后，可在浏览器中访问<code>http://cs-virtual-machine:6006/</code>。此时，点击Graph选项卡，可查看网络结构等信息，如图1-25所示。</p>
<p><center><img src="../assets/1-25.png" width = 350></center>
<center>图1-25 查看网络结构</center></p>
<h3 id="33">3.3 保存并测试网络</h3>
<p>&emsp;&emsp;网络训练完成后，需要将网络权值和偏置保存起来。首先基于numpy包实现网络参数的保存函数，如图1-26所示。</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">Record_Tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Recording tensor &quot;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot; ...&quot;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./record/&#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.dat&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">array</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1">#print(&quot;The range: [&quot; + str(np.min(array)) + &quot;:&quot; + str(np.max(array)) + &quot;]&quot;)</span>
    <span class="k">if</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">array</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">Record_Array1D</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">array</span><span class="p">))</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">Record_Array2D</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">array</span><span class="p">))</span> <span class="o">==</span> <span class="mi">3</span><span class="p">):</span>
                <span class="n">Record_Array3D</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Record_Array4D</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>
<p><center>图1-26 定义用于保存网络参数的<code>Record_Tensor</code>函数</center></p>
<p>&emsp;&emsp;训练完毕后，使用验证集测试CNN的预测准确度，并通过控制台打印结果。然后调用<code>Record_Tensor</code>将各层的参数保存成.dat格式的文件，如图1-27所示。</p>
<p><center><img src="../assets/1-27.png" width = 400></center>
<center>图1-27 测试网络预测准确度</center></p>
<p>&emsp;&emsp;由图1-27可知，总迭代次数为3000次，最终的预测准确度是95.13%。</p>
<h3 id="34">3.4 网络的前向推导</h3>
<p>&emsp;&emsp;本实验在Ubuntu虚拟机上进行CNN网络训练，并在PYNQ-Z2的异构平台上进行推导测试。网络推导的源文件是实验包的<code>systolic_app/mnist_cnn.ipynb</code>。</p>
<h4 id="_7">&spades; 网络参数的提取</h4>
<p>&emsp;&emsp;训练时，CNN的网络参数以<code>.dat</code>格式保存。推导时，首先需要使用虚拟机中的<code>~/tensorflow/dat2bin</code>工具，将其转换为<code>.bin</code>格式。</p>
<p>&emsp;&emsp;<code>mnist_cnn.ipynb</code>中定义了<code>readbinfile</code>函数以读取<code>.bin</code>格式的网络权值和偏置文件，如图1-28所示。</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">readbinfile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="n">size</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">z</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">data_float</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_float</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div>
<p><center>图1-28 读取.bin文件</center></p>
<p>&emsp;&emsp;调用<code>readbinfile</code>函数读取CNN的网络权值和偏置，如图1-29所示。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Read weights and bias from pre-tranined file</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Conv1:</span><span class="se">\t</span><span class="s2">loading weight... &quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">w_conv1</span> <span class="o">=</span> <span class="n">readbinfile</span><span class="p">(</span><span class="s2">&quot;./data/W_conv1.bin&quot;</span><span class="p">,</span> <span class="n">KERNEL_W1</span><span class="o">*</span><span class="n">KERNEL_W1</span><span class="o">*</span><span class="n">IN_CH1</span><span class="o">*</span><span class="n">OUT_CH1</span><span class="p">)</span>
<span class="n">w_conv1</span> <span class="o">=</span> <span class="n">w_conv1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">KERNEL_W1</span><span class="p">,</span> <span class="n">KERNEL_W1</span><span class="p">,</span> <span class="n">IN_CH1</span><span class="p">,</span> <span class="n">OUT_CH1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">KERNEL_W1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">KERNEL_W1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">IN_CH1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">ch_o</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">OUT_CH1</span><span class="p">):</span>
                <span class="n">W_conv1</span><span class="p">[</span><span class="n">ch_o</span><span class="p">][</span><span class="n">ch_i</span><span class="p">][</span><span class="n">r</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_conv1</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">ch_i</span><span class="p">][</span><span class="n">ch_o</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">loading bias... &quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">B_conv1</span> <span class="o">=</span> <span class="n">readbinfile</span><span class="p">(</span><span class="s2">&quot;./data/b_conv1.bin&quot;</span><span class="p">,</span><span class="n">OUT_CH1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">OUT_CH1</span><span class="p">):</span>
    <span class="n">b_conv1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">B_conv1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">)</span>

<span class="o">......</span>
</code></pre></div>
<p><center>图1-29 读取网络的权值和偏置参数</center></p>
<h4 id="ip">&spades; IP核的驱动/调用</h4>
<p>&emsp;&emsp;读取网络参数后，需要根据CNN的网络结构，在主程序中调用脉动阵列IP核与池化IP核，以完成CNN的前向推导过程。</p>
<p>&emsp;&emsp;<code>mnist_cnn.ipynb</code>还定义了脉动阵列IP核的驱动函数。该函数将IP核所需的各个参数通过特定的接口，经由AXI总线写入IP核当中，并通过特定接口读取IP核输出的数据，如图1-30所示。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 脉动阵列驱动函数</span>
<span class="k">def</span> <span class="nf">RunSystolic</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">din_a</span><span class="p">,</span> <span class="n">din_b</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x10</span><span class="p">,</span> <span class="n">din_a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x18</span><span class="p">,</span> <span class="n">din_a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x20</span><span class="p">,</span> <span class="n">din_b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x28</span><span class="p">,</span> <span class="n">din_a</span><span class="o">.</span><span class="n">physical_address</span><span class="p">)</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x30</span><span class="p">,</span> <span class="n">din_b</span><span class="o">.</span><span class="n">physical_address</span><span class="p">)</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x38</span><span class="p">,</span> <span class="n">bias</span><span class="o">.</span><span class="n">physical_address</span><span class="p">)</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mh">0x40</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">physical_address</span><span class="p">)</span>
    <span class="n">array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0x80</span><span class="p">)</span> <span class="o">|</span> <span class="mh">0x01</span><span class="p">)</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="p">((</span><span class="n">tp</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0x1</span><span class="p">):</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p><center>图1-30 脉动阵列IP核的驱动函数</center></p>
<p>&emsp;&emsp;池化IP核的驱动函数与<code>RunSystolic</code>函数类似，此处不再赘述。</p>
<div class="admonition info">
<p class="admonition-title">补充说明 <img alt="📣" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f4e3.svg" title=":mega:" /></p>
<p>&emsp;&emsp;脉动阵列IP核默认仅支持GEMM运算，所以如果想使用该IP核计算卷积，还需要另外实现卷积函数<code>hwConv</code>。这个函数负责完成特征图和卷积核的im2col操作，然后调用脉动阵列IP核，最后调整运算结果的尺寸和形状。</p>
</div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../overview/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 实验概述" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              实验概述
            </div>
          </div>
        </a>
      
      
        
        <a href="../step/" class="md-footer__link md-footer__link--next" aria-label="下一页: 实验步骤" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              实验步骤
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 - 2021 哈尔滨工业大学（深圳）
          </div>
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs"], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.fcfe8b6d.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.b1047164.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>